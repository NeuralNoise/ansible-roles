# Welcome to the InfluxDB configuration file.

# If hostname (on the OS) doesn't return a name that can be resolved by the other
# systems in the cluster, you'll have to set the hostname to an IP or something
# that can be resolved here.
hostname = "{{ influxdb_hostname }}"

bind-address = "{{ influxdb_bind_addr }}"

[logging]
# logging level can be one of "debug", "info", "warn" or "error"
level  = "{{ influxdb_log_level }}"
file   = "{{ influxdb_log_file }}"         # stdout to log to standard out

# Configure the admin server
[admin]
port   = {{ influxdb_admin_port }}              # binding is disabled if the port isn't set
assets = "/opt/influxdb/current/admin"

# Configure the http api
[api]
port     = {{ influxdb_api_port }}    # binding is disabled if the port isn't set
# ssl-port = 8084    # Ssl support is enabled if you set a port and cert
# ssl-cert = /path/to/cert.pem

# connections will timeout after this amount of time. Ensures that clients that misbehave 
# and keep alive connections they don't use won't end up connection a million times.
# However, if a request is taking longer than this to complete, could be a problem.
read-timeout = "{{ influxdb_read_timeout }}"

[input_plugins]

  # Configure the graphite api
  [input_plugins.graphite]
  enabled = {{ influxdb_graphite_plugin_enabled }}
  # port = {{ influxdb_graphite_plugin_port }}
  # database = "{{ influxdb_graphite_plugin_db }}"  # store graphite data in this database

# Raft configuration
[raft]
# The raft port should be open between all servers in a cluster.
# However, this port shouldn't be accessible from the internet.

port = {{ influxdb_raft_port }}

# Where the raft logs are stored. The user running InfluxDB will need read/write access.
dir  = "{{ influxdb_raft_log_dir }}"

# election-timeout = "1s"

[storage]
dir = "{{ influxdb_storage_dir }}"
# How many requests to potentially buffer in memory. If the buffer gets filled then writes
# will still be logged and once the local storage has caught up (or compacted) the writes
# will be replayed from the WAL
write-buffer-size = {{ influxdb_write_buffer }}

[cluster]
# A comma separated list of servers to seed
# this server. this is only relevant when the
# server is joining a new cluster. Otherwise
# the server will use the list of known servers
# prior to shutting down. Any server can be pointed to
# as a seed. It will find the Raft leader automatically.

# Here's an example. Note that the port on the host is the same as the raft port.
# seed-servers = ["hosta:8090","hostb:8090"]
{% if influxdb_seed_servers %}seed-servers = {{ influxdb_seed_servers }}{% endif %}

# Replication happens over a TCP connection with a Protobuf protocol.
# This port should be reachable between all servers in a cluster.
# However, this port shouldn't be accessible from the internet.

protobuf_port = {{ influxdb_proto_port }}
protobuf_timeout = "{{ influxdb_proto_timeout }}" # the write timeout on the protobuf conn any duration parseable by time.ParseDuration
protobuf_heartbeat = "{{ influxdb_proto_heartbeat }}" # the heartbeat interval between the servers. must be parseable by time.ParseDuration
protobuf_min_backoff = "{{ influxdb_proto_min_backoff }}" # the minimum backoff after a failed heartbeat attempt
protobuf_max_backoff = "{{ influxdb_proto_min_backoff }}" # the maximum backoff after a failed heartbeat attempt

# How many write requests to potentially buffer in memory per server. If the buffer gets filled then writes
# will still be logged and once the server has caught up (or come back online) the writes
# will be replayed from the WAL
write-buffer-size = {{ influxdb_write_buffer }}

# the maximum number of responses to buffer from remote nodes, if the
# expected number of responses exceed this number then querying will
# happen sequentially and the buffer size will be limited to this
# number
max-response-buffer-size = {{ influxdb_resp_buffer }}

# When queries get distributed out to shards, they go in parallel. This means that results can get buffered
# in memory since results will come in any order, but have to be processed in the correct time order.
# Setting this higher will give better performance, but you'll need more memory. Setting this to 1 will ensure
# that you don't need to buffer in memory, but you won't get the best performance.
concurrent-shard-query-limit = {{ influxdb_shard_q_limit }}

[sharding]
  # how many servers in the cluster should have a copy of each shard.
  # this will give you high availability and scalability on queries
  replication-factor = {{ influxdb_repl_factor }}

  [sharding.short-term]
  # each shard will have this period of time. Note that it's best to have
  # group by time() intervals on all queries be < than this setting. If they are
  # then the aggregate is calculated locally. Otherwise, all that data gets sent
  # over the network when doing a query.
  duration = "{{ influxdb_short_term_dur }}"

  # split will determine how many shards to split each duration into. For example,
  # if we created a shard for 2014-02-10 and split was set to 2. Then two shards
  # would be created that have the data for 2014-02-10. By default, data will
  # be split into those two shards deterministically by hashing the (database, series)
  # tuple. That means that data for a given series will be written to a single shard
  # making querying efficient. That can be overridden with the next option.
  split = {{ influxdb_short_term_split }}

  # You can override the split behavior to have the data for series that match a
  # given regex be randomly distributed across the shards for a given interval.
  # You can use this if you have a hot spot for a given time series writing more
  # data than a single server can handle. Most people won't have to resort to this
  # option. Also note that using this option means that queries will have to send
  # all data over the network so they won't be as efficient.
  # split-random = "/^hf.*/"

  [sharding.long-term]
  duration = "{{ influxdb_long_term_dur }}"
  split = {{ influxdb_long_term_split }}
  # split-random = "/^Hf.*/"

[wal]

dir   = "{{ influxdb_wal_dir }}"
flush-after = {{ influxdb_wal_flush }} # the number of writes after which wal will be flushed, 0 for flushing on every write
bookmark-after = {{ influxdb_wal_bookmark }} # the number of writes after which a bookmark will be created

# the number of writes after which an index entry is created pointing
# to the offset of the first request, default to 1k
index-after = {{ influxdb_wal_index }}

# the number of requests per one log file, if new requests came in a
# new log file will be created
requests-per-logfile = {{ influxdb_wal_logfile_req }}
